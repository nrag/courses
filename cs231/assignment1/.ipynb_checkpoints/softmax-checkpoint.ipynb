{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from cs231n.data_utils import load_CIFAR10\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax exercise\n",
    "\n",
    "*Complete and hand in this completed worksheet (including its outputs and any supporting code outside of the worksheet) with your assignment submission. For more details see the [assignments page](http://vision.stanford.edu/teaching/cs231n/assignments.html) on the course website.*\n",
    "\n",
    "This exercise is analogous to the SVM exercise. You will:\n",
    "\n",
    "- implement a fully-vectorized **loss function** for the Softmax classifier\n",
    "- implement the fully-vectorized expression for its **analytic gradient**\n",
    "- **check your implementation** with numerical gradient\n",
    "- use a validation set to **tune the learning rate and regularization** strength\n",
    "- **optimize** the loss function with **SGD**\n",
    "- **visualize** the final learned weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (49000, 3073)\n",
      "Train labels shape:  (49000,)\n",
      "Validation data shape:  (1000, 3073)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (1000, 3073)\n",
      "Test labels shape:  (1000,)\n",
      "dev data shape:  (500, 3073)\n",
      "dev labels shape:  (500,)\n"
     ]
    }
   ],
   "source": [
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000, num_dev=500):\n",
    "  \"\"\"\n",
    "  Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
    "  it for the linear classifier. These are the same steps as we used for the\n",
    "  SVM, but condensed to a single function.  \n",
    "  \"\"\"\n",
    "  # Load the raw CIFAR-10 data\n",
    "  cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'\n",
    "  X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "  \n",
    "  # subsample the data\n",
    "  mask = range(num_training, num_training + num_validation)\n",
    "  X_val = X_train[mask]\n",
    "  y_val = y_train[mask]\n",
    "  mask = range(num_training)\n",
    "  X_train = X_train[mask]\n",
    "  y_train = y_train[mask]\n",
    "  mask = range(num_test)\n",
    "  X_test = X_test[mask]\n",
    "  y_test = y_test[mask]\n",
    "  mask = np.random.choice(num_training, num_dev, replace=False)\n",
    "  X_dev = X_train[mask]\n",
    "  y_dev = y_train[mask]\n",
    "  \n",
    "  # Preprocessing: reshape the image data into rows\n",
    "  X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "  X_val = np.reshape(X_val, (X_val.shape[0], -1))\n",
    "  X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "  X_dev = np.reshape(X_dev, (X_dev.shape[0], -1))\n",
    "  \n",
    "  # Normalize the data: subtract the mean image\n",
    "  mean_image = np.mean(X_train, axis = 0)\n",
    "  X_train -= mean_image\n",
    "  X_val -= mean_image\n",
    "  X_test -= mean_image\n",
    "  X_dev -= mean_image\n",
    "  \n",
    "  # add bias dimension and transform into columns\n",
    "  X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
    "  X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n",
    "  X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
    "  X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))])\n",
    "  \n",
    "  return X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev\n",
    "\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev = get_CIFAR10_data()\n",
    "print 'Train data shape: ', X_train.shape\n",
    "print 'Train labels shape: ', y_train.shape\n",
    "print 'Validation data shape: ', X_val.shape\n",
    "print 'Validation labels shape: ', y_val.shape\n",
    "print 'Test data shape: ', X_test.shape\n",
    "print 'Test labels shape: ', y_test.shape\n",
    "print 'dev data shape: ', X_dev.shape\n",
    "print 'dev labels shape: ', y_dev.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Classifier\n",
    "\n",
    "Your code for this section will all be written inside **cs231n/classifiers/softmax.py**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.389398\n",
      "sanity check: 2.302585\n"
     ]
    }
   ],
   "source": [
    "# First implement the naive softmax loss function with nested loops.\n",
    "# Open the file cs231n/classifiers/softmax.py and implement the\n",
    "# softmax_loss_naive function.\n",
    "\n",
    "from cs231n.classifiers.softmax import softmax_loss_naive\n",
    "import time\n",
    "\n",
    "# Generate a random softmax weight matrix and use it to compute the loss.\n",
    "W = np.random.randn(3073, 10) * 0.0001\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As a rough sanity check, our loss should be something close to -log(0.1).\n",
    "print 'loss: %f' % loss\n",
    "print 'sanity check: %f' % (-np.log(0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inline Question 1:\n",
    "Why do we expect our loss to be close to -log(0.1)? Explain briefly.**\n",
    "\n",
    "**Your answer:** *Fill this in*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical: -1.054971 analytic: -1.054971, relative error: 2.621937e-08\n",
      "numerical: -0.743452 analytic: -0.743452, relative error: 9.235295e-08\n",
      "numerical: 1.217158 analytic: 1.217158, relative error: 6.145801e-08\n",
      "numerical: -0.672326 analytic: -0.672327, relative error: 1.353952e-07\n",
      "numerical: 0.148393 analytic: 0.148393, relative error: 7.821462e-08\n",
      "numerical: -0.582768 analytic: -0.582768, relative error: 7.083973e-08\n",
      "numerical: 1.895743 analytic: 1.895743, relative error: 1.786510e-08\n",
      "numerical: 0.028802 analytic: 0.028802, relative error: 1.859862e-06\n",
      "numerical: 2.481232 analytic: 2.481232, relative error: 2.687926e-08\n",
      "numerical: -0.073506 analytic: -0.073506, relative error: 2.727690e-07\n",
      "numerical: 1.448511 analytic: 1.448511, relative error: 3.783546e-08\n",
      "numerical: -2.214118 analytic: -2.214118, relative error: 1.554251e-08\n",
      "numerical: 1.374268 analytic: 1.374268, relative error: 1.913740e-08\n",
      "numerical: 2.258477 analytic: 2.258476, relative error: 4.151715e-08\n",
      "numerical: -0.791978 analytic: -0.791978, relative error: 3.463534e-09\n",
      "numerical: 0.778552 analytic: 0.778552, relative error: 2.727571e-08\n",
      "numerical: 0.461550 analytic: 0.461550, relative error: 9.770850e-08\n",
      "numerical: -0.129847 analytic: -0.129847, relative error: 1.133288e-07\n",
      "numerical: -0.306033 analytic: -0.306033, relative error: 4.661261e-08\n",
      "numerical: 2.415611 analytic: 2.415611, relative error: 2.603234e-08\n"
     ]
    }
   ],
   "source": [
    "# Complete the implementation of softmax_loss_naive and implement a (naive)\n",
    "# version of the gradient that uses nested loops.\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As we did for the SVM, use numeric gradient checking as a debugging tool.\n",
    "# The numeric gradient should be close to the analytic gradient.\n",
    "from cs231n.gradient_check import grad_check_sparse\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 0.0)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)\n",
    "\n",
    "# similar to SVM case, do another gradient check with regularization\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 1e2)\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 1e2)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive loss: 2.389398e+00 computed in 0.003835s\n",
      "vectorized loss: 2.389398e+00 computed in 0.002651s\n",
      "Loss difference: 0.000000\n",
      "Gradient difference: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now that we have a naive implementation of the softmax loss function and its gradient,\n",
    "# implement a vectorized version in softmax_loss_vectorized.\n",
    "# The two versions should compute the same results, but the vectorized version should be\n",
    "# much faster.\n",
    "tic = time.time()\n",
    "loss_naive, grad_naive = softmax_loss_naive(W, X_dev, y_dev, 0.00001)\n",
    "toc = time.time()\n",
    "print 'naive loss: %e computed in %fs' % (loss_naive, toc - tic)\n",
    "\n",
    "from cs231n.classifiers.softmax import softmax_loss_vectorized\n",
    "tic = time.time()\n",
    "loss_vectorized, grad_vectorized = softmax_loss_vectorized(W, X_dev, y_dev, 0.00001)\n",
    "toc = time.time()\n",
    "print 'vectorized loss: %e computed in %fs' % (loss_vectorized, toc - tic)\n",
    "\n",
    "# As we did for the SVM, we use the Frobenius norm to compare the two versions\n",
    "# of the gradient.\n",
    "grad_difference = np.linalg.norm(grad_naive - grad_vectorized, ord='fro')\n",
    "print 'Loss difference: %f' % np.abs(loss_naive - loss_vectorized)\n",
    "print 'Gradient difference: %f' % grad_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "X_train (49000, 3073)\n",
      "lr 1.000000e-05 reg 1.000000e-03 train accuracy: 0.305204 val accuracy: 0.299000\n",
      "lr 1.000000e-05 reg 1.373824e-03 train accuracy: 0.308714 val accuracy: 0.307000\n",
      "lr 1.000000e-05 reg 1.887392e-03 train accuracy: 0.313796 val accuracy: 0.308000\n",
      "lr 1.000000e-05 reg 2.592944e-03 train accuracy: 0.285490 val accuracy: 0.271000\n",
      "lr 1.000000e-05 reg 3.562248e-03 train accuracy: 0.318755 val accuracy: 0.303000\n",
      "lr 1.000000e-05 reg 4.893901e-03 train accuracy: 0.354735 val accuracy: 0.349000\n",
      "lr 1.000000e-05 reg 6.723358e-03 train accuracy: 0.309306 val accuracy: 0.304000\n",
      "lr 1.000000e-05 reg 9.236709e-03 train accuracy: 0.329755 val accuracy: 0.325000\n",
      "lr 1.000000e-05 reg 1.268961e-02 train accuracy: 0.328531 val accuracy: 0.324000\n",
      "lr 1.000000e-05 reg 1.743329e-02 train accuracy: 0.308408 val accuracy: 0.299000\n",
      "lr 1.000000e-05 reg 2.395027e-02 train accuracy: 0.308531 val accuracy: 0.315000\n",
      "lr 1.000000e-05 reg 3.290345e-02 train accuracy: 0.259388 val accuracy: 0.251000\n",
      "lr 1.000000e-05 reg 4.520354e-02 train accuracy: 0.297673 val accuracy: 0.305000\n",
      "lr 1.000000e-05 reg 6.210169e-02 train accuracy: 0.319429 val accuracy: 0.306000\n",
      "lr 1.000000e-05 reg 8.531679e-02 train accuracy: 0.320082 val accuracy: 0.305000\n",
      "lr 1.000000e-05 reg 1.172102e-01 train accuracy: 0.318449 val accuracy: 0.338000\n",
      "lr 1.000000e-05 reg 1.610262e-01 train accuracy: 0.297000 val accuracy: 0.307000\n",
      "lr 1.000000e-05 reg 2.212216e-01 train accuracy: 0.339959 val accuracy: 0.327000\n",
      "lr 1.000000e-05 reg 3.039195e-01 train accuracy: 0.328061 val accuracy: 0.306000\n",
      "lr 1.000000e-05 reg 4.175319e-01 train accuracy: 0.304939 val accuracy: 0.296000\n",
      "lr 1.000000e-05 reg 5.736153e-01 train accuracy: 0.342122 val accuracy: 0.332000\n",
      "lr 1.000000e-05 reg 7.880463e-01 train accuracy: 0.333061 val accuracy: 0.293000\n",
      "lr 1.000000e-05 reg 1.082637e+00 train accuracy: 0.336755 val accuracy: 0.336000\n",
      "lr 1.000000e-05 reg 1.487352e+00 train accuracy: 0.327653 val accuracy: 0.324000\n",
      "lr 1.000000e-05 reg 2.043360e+00 train accuracy: 0.326571 val accuracy: 0.310000\n",
      "lr 1.000000e-05 reg 2.807216e+00 train accuracy: 0.309980 val accuracy: 0.321000\n",
      "lr 1.000000e-05 reg 3.856620e+00 train accuracy: 0.293551 val accuracy: 0.295000\n",
      "lr 1.000000e-05 reg 5.298317e+00 train accuracy: 0.291388 val accuracy: 0.286000\n",
      "lr 1.000000e-05 reg 7.278954e+00 train accuracy: 0.321102 val accuracy: 0.298000\n",
      "lr 1.000000e-05 reg 1.000000e+01 train accuracy: 0.316143 val accuracy: 0.307000\n",
      "lr 1.425103e-05 reg 1.000000e-03 train accuracy: 0.284184 val accuracy: 0.258000\n",
      "lr 1.425103e-05 reg 1.373824e-03 train accuracy: 0.265980 val accuracy: 0.260000\n",
      "lr 1.425103e-05 reg 1.887392e-03 train accuracy: 0.285388 val accuracy: 0.297000\n",
      "lr 1.425103e-05 reg 2.592944e-03 train accuracy: 0.322857 val accuracy: 0.306000\n",
      "lr 1.425103e-05 reg 3.562248e-03 train accuracy: 0.328918 val accuracy: 0.334000\n",
      "lr 1.425103e-05 reg 4.893901e-03 train accuracy: 0.341816 val accuracy: 0.322000\n",
      "lr 1.425103e-05 reg 6.723358e-03 train accuracy: 0.295224 val accuracy: 0.274000\n",
      "lr 1.425103e-05 reg 9.236709e-03 train accuracy: 0.319449 val accuracy: 0.321000\n",
      "lr 1.425103e-05 reg 1.268961e-02 train accuracy: 0.293020 val accuracy: 0.284000\n",
      "lr 1.425103e-05 reg 1.743329e-02 train accuracy: 0.288939 val accuracy: 0.296000\n",
      "lr 1.425103e-05 reg 2.395027e-02 train accuracy: 0.259265 val accuracy: 0.272000\n",
      "lr 1.425103e-05 reg 3.290345e-02 train accuracy: 0.268449 val accuracy: 0.275000\n",
      "lr 1.425103e-05 reg 4.520354e-02 train accuracy: 0.302857 val accuracy: 0.310000\n",
      "lr 1.425103e-05 reg 6.210169e-02 train accuracy: 0.291776 val accuracy: 0.275000\n",
      "lr 1.425103e-05 reg 8.531679e-02 train accuracy: 0.285735 val accuracy: 0.286000\n",
      "lr 1.425103e-05 reg 1.172102e-01 train accuracy: 0.308796 val accuracy: 0.309000\n",
      "lr 1.425103e-05 reg 1.610262e-01 train accuracy: 0.287204 val accuracy: 0.282000\n",
      "lr 1.425103e-05 reg 2.212216e-01 train accuracy: 0.337327 val accuracy: 0.325000\n",
      "lr 1.425103e-05 reg 3.039195e-01 train accuracy: 0.297041 val accuracy: 0.273000\n",
      "lr 1.425103e-05 reg 4.175319e-01 train accuracy: 0.270571 val accuracy: 0.272000\n",
      "lr 1.425103e-05 reg 5.736153e-01 train accuracy: 0.268245 val accuracy: 0.275000\n",
      "lr 1.425103e-05 reg 7.880463e-01 train accuracy: 0.321102 val accuracy: 0.314000\n",
      "lr 1.425103e-05 reg 1.082637e+00 train accuracy: 0.350878 val accuracy: 0.332000\n",
      "lr 1.425103e-05 reg 1.487352e+00 train accuracy: 0.294816 val accuracy: 0.276000\n",
      "lr 1.425103e-05 reg 2.043360e+00 train accuracy: 0.285816 val accuracy: 0.295000\n",
      "lr 1.425103e-05 reg 2.807216e+00 train accuracy: 0.307816 val accuracy: 0.311000\n",
      "lr 1.425103e-05 reg 3.856620e+00 train accuracy: 0.308857 val accuracy: 0.313000\n",
      "lr 1.425103e-05 reg 5.298317e+00 train accuracy: 0.263286 val accuracy: 0.259000\n",
      "lr 1.425103e-05 reg 7.278954e+00 train accuracy: 0.311143 val accuracy: 0.278000\n",
      "lr 1.425103e-05 reg 1.000000e+01 train accuracy: 0.269102 val accuracy: 0.273000\n",
      "lr 2.030918e-05 reg 1.000000e-03 train accuracy: 0.288306 val accuracy: 0.273000\n",
      "lr 2.030918e-05 reg 1.373824e-03 train accuracy: 0.272735 val accuracy: 0.274000\n",
      "lr 2.030918e-05 reg 1.887392e-03 train accuracy: 0.293898 val accuracy: 0.292000\n",
      "lr 2.030918e-05 reg 2.592944e-03 train accuracy: 0.295082 val accuracy: 0.288000\n",
      "lr 2.030918e-05 reg 3.562248e-03 train accuracy: 0.272816 val accuracy: 0.259000\n",
      "lr 2.030918e-05 reg 4.893901e-03 train accuracy: 0.282735 val accuracy: 0.279000\n",
      "lr 2.030918e-05 reg 6.723358e-03 train accuracy: 0.319061 val accuracy: 0.294000\n",
      "lr 2.030918e-05 reg 9.236709e-03 train accuracy: 0.284102 val accuracy: 0.288000\n",
      "lr 2.030918e-05 reg 1.268961e-02 train accuracy: 0.274939 val accuracy: 0.266000\n",
      "lr 2.030918e-05 reg 1.743329e-02 train accuracy: 0.275449 val accuracy: 0.266000\n",
      "lr 2.030918e-05 reg 2.395027e-02 train accuracy: 0.239673 val accuracy: 0.239000\n",
      "lr 2.030918e-05 reg 3.290345e-02 train accuracy: 0.281163 val accuracy: 0.269000\n",
      "lr 2.030918e-05 reg 4.520354e-02 train accuracy: 0.308878 val accuracy: 0.300000\n",
      "lr 2.030918e-05 reg 6.210169e-02 train accuracy: 0.328592 val accuracy: 0.319000\n",
      "lr 2.030918e-05 reg 8.531679e-02 train accuracy: 0.295245 val accuracy: 0.297000\n",
      "lr 2.030918e-05 reg 1.172102e-01 train accuracy: 0.282224 val accuracy: 0.270000\n",
      "lr 2.030918e-05 reg 1.610262e-01 train accuracy: 0.290980 val accuracy: 0.272000\n",
      "lr 2.030918e-05 reg 2.212216e-01 train accuracy: 0.277408 val accuracy: 0.266000\n",
      "lr 2.030918e-05 reg 3.039195e-01 train accuracy: 0.266020 val accuracy: 0.288000\n",
      "lr 2.030918e-05 reg 4.175319e-01 train accuracy: 0.289510 val accuracy: 0.312000\n",
      "lr 2.030918e-05 reg 5.736153e-01 train accuracy: 0.274755 val accuracy: 0.283000\n",
      "lr 2.030918e-05 reg 7.880463e-01 train accuracy: 0.297551 val accuracy: 0.284000\n",
      "lr 2.030918e-05 reg 1.082637e+00 train accuracy: 0.319816 val accuracy: 0.307000\n",
      "lr 2.030918e-05 reg 1.487352e+00 train accuracy: 0.326878 val accuracy: 0.321000\n",
      "lr 2.030918e-05 reg 2.043360e+00 train accuracy: 0.261694 val accuracy: 0.247000\n",
      "lr 2.030918e-05 reg 2.807216e+00 train accuracy: 0.290673 val accuracy: 0.291000\n",
      "lr 2.030918e-05 reg 3.856620e+00 train accuracy: 0.296286 val accuracy: 0.309000\n",
      "lr 2.030918e-05 reg 5.298317e+00 train accuracy: 0.288224 val accuracy: 0.269000\n",
      "lr 2.030918e-05 reg 7.278954e+00 train accuracy: 0.312857 val accuracy: 0.290000\n",
      "lr 2.030918e-05 reg 1.000000e+01 train accuracy: 0.303510 val accuracy: 0.313000\n",
      "lr 2.894266e-05 reg 1.000000e-03 train accuracy: 0.246653 val accuracy: 0.237000\n",
      "lr 2.894266e-05 reg 1.373824e-03 train accuracy: 0.304571 val accuracy: 0.308000\n",
      "lr 2.894266e-05 reg 1.887392e-03 train accuracy: 0.322204 val accuracy: 0.333000\n",
      "lr 2.894266e-05 reg 2.592944e-03 train accuracy: 0.210286 val accuracy: 0.218000\n",
      "lr 2.894266e-05 reg 3.562248e-03 train accuracy: 0.299122 val accuracy: 0.311000\n",
      "lr 2.894266e-05 reg 4.893901e-03 train accuracy: 0.248980 val accuracy: 0.232000\n",
      "lr 2.894266e-05 reg 6.723358e-03 train accuracy: 0.284286 val accuracy: 0.299000\n",
      "lr 2.894266e-05 reg 9.236709e-03 train accuracy: 0.310204 val accuracy: 0.289000\n",
      "lr 2.894266e-05 reg 1.268961e-02 train accuracy: 0.300837 val accuracy: 0.302000\n",
      "lr 2.894266e-05 reg 1.743329e-02 train accuracy: 0.273980 val accuracy: 0.249000\n",
      "lr 2.894266e-05 reg 2.395027e-02 train accuracy: 0.291449 val accuracy: 0.272000\n",
      "lr 2.894266e-05 reg 3.290345e-02 train accuracy: 0.277102 val accuracy: 0.275000\n",
      "lr 2.894266e-05 reg 4.520354e-02 train accuracy: 0.292184 val accuracy: 0.296000\n",
      "lr 2.894266e-05 reg 6.210169e-02 train accuracy: 0.285367 val accuracy: 0.273000\n",
      "lr 2.894266e-05 reg 8.531679e-02 train accuracy: 0.232469 val accuracy: 0.221000\n",
      "lr 2.894266e-05 reg 1.172102e-01 train accuracy: 0.262204 val accuracy: 0.254000\n",
      "lr 2.894266e-05 reg 1.610262e-01 train accuracy: 0.298306 val accuracy: 0.271000\n",
      "lr 2.894266e-05 reg 2.212216e-01 train accuracy: 0.340082 val accuracy: 0.302000\n",
      "lr 2.894266e-05 reg 3.039195e-01 train accuracy: 0.293959 val accuracy: 0.289000\n",
      "lr 2.894266e-05 reg 4.175319e-01 train accuracy: 0.321510 val accuracy: 0.314000\n",
      "lr 2.894266e-05 reg 5.736153e-01 train accuracy: 0.317939 val accuracy: 0.292000\n",
      "lr 2.894266e-05 reg 7.880463e-01 train accuracy: 0.296490 val accuracy: 0.292000\n",
      "lr 2.894266e-05 reg 1.082637e+00 train accuracy: 0.278347 val accuracy: 0.263000\n",
      "lr 2.894266e-05 reg 1.487352e+00 train accuracy: 0.286184 val accuracy: 0.289000\n",
      "lr 2.894266e-05 reg 2.043360e+00 train accuracy: 0.283571 val accuracy: 0.279000\n",
      "lr 2.894266e-05 reg 2.807216e+00 train accuracy: 0.292408 val accuracy: 0.288000\n",
      "lr 2.894266e-05 reg 3.856620e+00 train accuracy: 0.239204 val accuracy: 0.229000\n",
      "lr 2.894266e-05 reg 5.298317e+00 train accuracy: 0.299898 val accuracy: 0.321000\n",
      "lr 2.894266e-05 reg 7.278954e+00 train accuracy: 0.313224 val accuracy: 0.314000\n",
      "lr 2.894266e-05 reg 1.000000e+01 train accuracy: 0.276714 val accuracy: 0.282000\n",
      "lr 4.124626e-05 reg 1.000000e-03 train accuracy: 0.239714 val accuracy: 0.234000\n",
      "lr 4.124626e-05 reg 1.373824e-03 train accuracy: 0.297102 val accuracy: 0.293000\n",
      "lr 4.124626e-05 reg 1.887392e-03 train accuracy: 0.273551 val accuracy: 0.263000\n",
      "lr 4.124626e-05 reg 2.592944e-03 train accuracy: 0.312367 val accuracy: 0.310000\n",
      "lr 4.124626e-05 reg 3.562248e-03 train accuracy: 0.293286 val accuracy: 0.303000\n",
      "lr 4.124626e-05 reg 4.893901e-03 train accuracy: 0.267653 val accuracy: 0.296000\n",
      "lr 4.124626e-05 reg 6.723358e-03 train accuracy: 0.282408 val accuracy: 0.293000\n",
      "lr 4.124626e-05 reg 9.236709e-03 train accuracy: 0.304306 val accuracy: 0.300000\n",
      "lr 4.124626e-05 reg 1.268961e-02 train accuracy: 0.276163 val accuracy: 0.268000\n",
      "lr 4.124626e-05 reg 1.743329e-02 train accuracy: 0.290327 val accuracy: 0.293000\n",
      "lr 4.124626e-05 reg 2.395027e-02 train accuracy: 0.283857 val accuracy: 0.304000\n",
      "lr 4.124626e-05 reg 3.290345e-02 train accuracy: 0.237755 val accuracy: 0.223000\n",
      "lr 4.124626e-05 reg 4.520354e-02 train accuracy: 0.286306 val accuracy: 0.278000\n",
      "lr 4.124626e-05 reg 6.210169e-02 train accuracy: 0.300531 val accuracy: 0.287000\n",
      "lr 4.124626e-05 reg 8.531679e-02 train accuracy: 0.309184 val accuracy: 0.307000\n",
      "lr 4.124626e-05 reg 1.172102e-01 train accuracy: 0.279837 val accuracy: 0.265000\n",
      "lr 4.124626e-05 reg 1.610262e-01 train accuracy: 0.273612 val accuracy: 0.282000\n",
      "lr 4.124626e-05 reg 2.212216e-01 train accuracy: 0.276510 val accuracy: 0.249000\n",
      "lr 4.124626e-05 reg 3.039195e-01 train accuracy: 0.287816 val accuracy: 0.294000\n",
      "lr 4.124626e-05 reg 4.175319e-01 train accuracy: 0.258102 val accuracy: 0.256000\n",
      "lr 4.124626e-05 reg 5.736153e-01 train accuracy: 0.224000 val accuracy: 0.220000\n",
      "lr 4.124626e-05 reg 7.880463e-01 train accuracy: 0.270041 val accuracy: 0.274000\n",
      "lr 4.124626e-05 reg 1.082637e+00 train accuracy: 0.263000 val accuracy: 0.269000\n",
      "lr 4.124626e-05 reg 1.487352e+00 train accuracy: 0.314714 val accuracy: 0.314000\n",
      "lr 4.124626e-05 reg 2.043360e+00 train accuracy: 0.273102 val accuracy: 0.253000\n",
      "lr 4.124626e-05 reg 2.807216e+00 train accuracy: 0.252469 val accuracy: 0.246000\n",
      "lr 4.124626e-05 reg 3.856620e+00 train accuracy: 0.258143 val accuracy: 0.261000\n",
      "lr 4.124626e-05 reg 5.298317e+00 train accuracy: 0.289898 val accuracy: 0.282000\n",
      "lr 4.124626e-05 reg 7.278954e+00 train accuracy: 0.287163 val accuracy: 0.304000\n",
      "lr 4.124626e-05 reg 1.000000e+01 train accuracy: 0.263837 val accuracy: 0.276000\n",
      "lr 5.878016e-05 reg 1.000000e-03 train accuracy: 0.283327 val accuracy: 0.271000\n",
      "lr 5.878016e-05 reg 1.373824e-03 train accuracy: 0.293102 val accuracy: 0.278000\n",
      "lr 5.878016e-05 reg 1.887392e-03 train accuracy: 0.304673 val accuracy: 0.289000\n",
      "lr 5.878016e-05 reg 2.592944e-03 train accuracy: 0.339653 val accuracy: 0.336000\n",
      "lr 5.878016e-05 reg 3.562248e-03 train accuracy: 0.280714 val accuracy: 0.239000\n",
      "lr 5.878016e-05 reg 4.893901e-03 train accuracy: 0.302347 val accuracy: 0.302000\n",
      "lr 5.878016e-05 reg 6.723358e-03 train accuracy: 0.304490 val accuracy: 0.295000\n",
      "lr 5.878016e-05 reg 9.236709e-03 train accuracy: 0.293449 val accuracy: 0.294000\n",
      "lr 5.878016e-05 reg 1.268961e-02 train accuracy: 0.247224 val accuracy: 0.234000\n",
      "lr 5.878016e-05 reg 1.743329e-02 train accuracy: 0.269429 val accuracy: 0.283000\n",
      "lr 5.878016e-05 reg 2.395027e-02 train accuracy: 0.260102 val accuracy: 0.246000\n",
      "lr 5.878016e-05 reg 3.290345e-02 train accuracy: 0.276020 val accuracy: 0.265000\n",
      "lr 5.878016e-05 reg 4.520354e-02 train accuracy: 0.313612 val accuracy: 0.309000\n",
      "lr 5.878016e-05 reg 6.210169e-02 train accuracy: 0.277735 val accuracy: 0.313000\n",
      "lr 5.878016e-05 reg 8.531679e-02 train accuracy: 0.253184 val accuracy: 0.250000\n",
      "lr 5.878016e-05 reg 1.172102e-01 train accuracy: 0.300980 val accuracy: 0.300000\n",
      "lr 5.878016e-05 reg 1.610262e-01 train accuracy: 0.279776 val accuracy: 0.258000\n",
      "lr 5.878016e-05 reg 2.212216e-01 train accuracy: 0.293449 val accuracy: 0.281000\n",
      "lr 5.878016e-05 reg 3.039195e-01 train accuracy: 0.235755 val accuracy: 0.232000\n",
      "lr 5.878016e-05 reg 4.175319e-01 train accuracy: 0.304102 val accuracy: 0.310000\n",
      "lr 5.878016e-05 reg 5.736153e-01 train accuracy: 0.292531 val accuracy: 0.293000\n",
      "lr 5.878016e-05 reg 7.880463e-01 train accuracy: 0.283469 val accuracy: 0.279000\n",
      "lr 5.878016e-05 reg 1.082637e+00 train accuracy: 0.300429 val accuracy: 0.308000\n",
      "lr 5.878016e-05 reg 1.487352e+00 train accuracy: 0.295653 val accuracy: 0.296000\n",
      "lr 5.878016e-05 reg 2.043360e+00 train accuracy: 0.269571 val accuracy: 0.275000\n",
      "lr 5.878016e-05 reg 2.807216e+00 train accuracy: 0.275265 val accuracy: 0.270000\n",
      "lr 5.878016e-05 reg 3.856620e+00 train accuracy: 0.273571 val accuracy: 0.265000\n",
      "lr 5.878016e-05 reg 5.298317e+00 train accuracy: 0.264939 val accuracy: 0.276000\n",
      "lr 5.878016e-05 reg 7.278954e+00 train accuracy: 0.289816 val accuracy: 0.297000\n",
      "lr 5.878016e-05 reg 1.000000e+01 train accuracy: 0.277408 val accuracy: 0.268000\n",
      "lr 8.376776e-05 reg 1.000000e-03 train accuracy: 0.273959 val accuracy: 0.281000\n",
      "lr 8.376776e-05 reg 1.373824e-03 train accuracy: 0.331878 val accuracy: 0.319000\n",
      "lr 8.376776e-05 reg 1.887392e-03 train accuracy: 0.282327 val accuracy: 0.273000\n",
      "lr 8.376776e-05 reg 2.592944e-03 train accuracy: 0.296367 val accuracy: 0.275000\n",
      "lr 8.376776e-05 reg 3.562248e-03 train accuracy: 0.301694 val accuracy: 0.305000\n",
      "lr 8.376776e-05 reg 4.893901e-03 train accuracy: 0.273653 val accuracy: 0.273000\n",
      "lr 8.376776e-05 reg 6.723358e-03 train accuracy: 0.288694 val accuracy: 0.276000\n",
      "lr 8.376776e-05 reg 9.236709e-03 train accuracy: 0.316673 val accuracy: 0.325000\n",
      "lr 8.376776e-05 reg 1.268961e-02 train accuracy: 0.249918 val accuracy: 0.259000\n",
      "lr 8.376776e-05 reg 1.743329e-02 train accuracy: 0.299306 val accuracy: 0.292000\n",
      "lr 8.376776e-05 reg 2.395027e-02 train accuracy: 0.296306 val accuracy: 0.289000\n",
      "lr 8.376776e-05 reg 3.290345e-02 train accuracy: 0.305939 val accuracy: 0.287000\n",
      "lr 8.376776e-05 reg 4.520354e-02 train accuracy: 0.276041 val accuracy: 0.272000\n",
      "lr 8.376776e-05 reg 6.210169e-02 train accuracy: 0.250612 val accuracy: 0.244000\n",
      "lr 8.376776e-05 reg 8.531679e-02 train accuracy: 0.298388 val accuracy: 0.288000\n",
      "lr 8.376776e-05 reg 1.172102e-01 train accuracy: 0.281796 val accuracy: 0.273000\n",
      "lr 8.376776e-05 reg 1.610262e-01 train accuracy: 0.286612 val accuracy: 0.285000\n",
      "lr 8.376776e-05 reg 2.212216e-01 train accuracy: 0.305184 val accuracy: 0.303000\n",
      "lr 8.376776e-05 reg 3.039195e-01 train accuracy: 0.275061 val accuracy: 0.241000\n",
      "lr 8.376776e-05 reg 4.175319e-01 train accuracy: 0.299469 val accuracy: 0.301000\n",
      "lr 8.376776e-05 reg 5.736153e-01 train accuracy: 0.271816 val accuracy: 0.286000\n",
      "lr 8.376776e-05 reg 7.880463e-01 train accuracy: 0.324163 val accuracy: 0.312000\n",
      "lr 8.376776e-05 reg 1.082637e+00 train accuracy: 0.287000 val accuracy: 0.276000\n",
      "lr 8.376776e-05 reg 1.487352e+00 train accuracy: 0.269122 val accuracy: 0.266000\n",
      "lr 8.376776e-05 reg 2.043360e+00 train accuracy: 0.255082 val accuracy: 0.259000\n",
      "lr 8.376776e-05 reg 2.807216e+00 train accuracy: 0.298429 val accuracy: 0.308000\n",
      "lr 8.376776e-05 reg 3.856620e+00 train accuracy: 0.282143 val accuracy: 0.268000\n",
      "lr 8.376776e-05 reg 5.298317e+00 train accuracy: 0.277265 val accuracy: 0.288000\n",
      "lr 8.376776e-05 reg 7.278954e+00 train accuracy: 0.265980 val accuracy: 0.266000\n",
      "lr 8.376776e-05 reg 1.000000e+01 train accuracy: 0.252633 val accuracy: 0.249000\n",
      "lr 1.193777e-04 reg 1.000000e-03 train accuracy: 0.287102 val accuracy: 0.285000\n",
      "lr 1.193777e-04 reg 1.373824e-03 train accuracy: 0.287286 val accuracy: 0.295000\n",
      "lr 1.193777e-04 reg 1.887392e-03 train accuracy: 0.311531 val accuracy: 0.309000\n",
      "lr 1.193777e-04 reg 2.592944e-03 train accuracy: 0.299633 val accuracy: 0.295000\n",
      "lr 1.193777e-04 reg 3.562248e-03 train accuracy: 0.276102 val accuracy: 0.258000\n",
      "lr 1.193777e-04 reg 4.893901e-03 train accuracy: 0.277878 val accuracy: 0.251000\n",
      "lr 1.193777e-04 reg 6.723358e-03 train accuracy: 0.256918 val accuracy: 0.258000\n",
      "lr 1.193777e-04 reg 9.236709e-03 train accuracy: 0.284163 val accuracy: 0.294000\n",
      "lr 1.193777e-04 reg 1.268961e-02 train accuracy: 0.295143 val accuracy: 0.302000\n",
      "lr 1.193777e-04 reg 1.743329e-02 train accuracy: 0.227102 val accuracy: 0.233000\n",
      "lr 1.193777e-04 reg 2.395027e-02 train accuracy: 0.327571 val accuracy: 0.335000\n",
      "lr 1.193777e-04 reg 3.290345e-02 train accuracy: 0.274306 val accuracy: 0.254000\n",
      "lr 1.193777e-04 reg 4.520354e-02 train accuracy: 0.253163 val accuracy: 0.231000\n",
      "lr 1.193777e-04 reg 6.210169e-02 train accuracy: 0.281735 val accuracy: 0.278000\n",
      "lr 1.193777e-04 reg 8.531679e-02 train accuracy: 0.263000 val accuracy: 0.262000\n",
      "lr 1.193777e-04 reg 1.172102e-01 train accuracy: 0.289878 val accuracy: 0.281000\n",
      "lr 1.193777e-04 reg 1.610262e-01 train accuracy: 0.327041 val accuracy: 0.310000\n",
      "lr 1.193777e-04 reg 2.212216e-01 train accuracy: 0.287469 val accuracy: 0.293000\n",
      "lr 1.193777e-04 reg 3.039195e-01 train accuracy: 0.302837 val accuracy: 0.327000\n",
      "lr 1.193777e-04 reg 4.175319e-01 train accuracy: 0.258633 val accuracy: 0.240000\n",
      "lr 1.193777e-04 reg 5.736153e-01 train accuracy: 0.303796 val accuracy: 0.312000\n",
      "lr 1.193777e-04 reg 7.880463e-01 train accuracy: 0.291898 val accuracy: 0.268000\n",
      "lr 1.193777e-04 reg 1.082637e+00 train accuracy: 0.292959 val accuracy: 0.284000\n",
      "lr 1.193777e-04 reg 1.487352e+00 train accuracy: 0.290694 val accuracy: 0.275000\n",
      "lr 1.193777e-04 reg 2.043360e+00 train accuracy: 0.300327 val accuracy: 0.303000\n",
      "lr 1.193777e-04 reg 2.807216e+00 train accuracy: 0.261245 val accuracy: 0.267000\n",
      "lr 1.193777e-04 reg 3.856620e+00 train accuracy: 0.319204 val accuracy: 0.306000\n",
      "lr 1.193777e-04 reg 5.298317e+00 train accuracy: 0.266673 val accuracy: 0.294000\n",
      "lr 1.193777e-04 reg 7.278954e+00 train accuracy: 0.280571 val accuracy: 0.288000\n",
      "lr 1.193777e-04 reg 1.000000e+01 train accuracy: 0.250469 val accuracy: 0.258000\n",
      "lr 1.701254e-04 reg 1.000000e-03 train accuracy: 0.264347 val accuracy: 0.272000\n",
      "lr 1.701254e-04 reg 1.373824e-03 train accuracy: 0.316469 val accuracy: 0.305000\n",
      "lr 1.701254e-04 reg 1.887392e-03 train accuracy: 0.227102 val accuracy: 0.212000\n",
      "lr 1.701254e-04 reg 2.592944e-03 train accuracy: 0.271245 val accuracy: 0.281000\n",
      "lr 1.701254e-04 reg 3.562248e-03 train accuracy: 0.259510 val accuracy: 0.238000\n",
      "lr 1.701254e-04 reg 4.893901e-03 train accuracy: 0.297714 val accuracy: 0.278000\n",
      "lr 1.701254e-04 reg 6.723358e-03 train accuracy: 0.276388 val accuracy: 0.259000\n",
      "lr 1.701254e-04 reg 9.236709e-03 train accuracy: 0.251612 val accuracy: 0.237000\n",
      "lr 1.701254e-04 reg 1.268961e-02 train accuracy: 0.316429 val accuracy: 0.313000\n",
      "lr 1.701254e-04 reg 1.743329e-02 train accuracy: 0.318694 val accuracy: 0.312000\n",
      "lr 1.701254e-04 reg 2.395027e-02 train accuracy: 0.301184 val accuracy: 0.300000\n",
      "lr 1.701254e-04 reg 3.290345e-02 train accuracy: 0.253204 val accuracy: 0.238000\n",
      "lr 1.701254e-04 reg 4.520354e-02 train accuracy: 0.301694 val accuracy: 0.284000\n",
      "lr 1.701254e-04 reg 6.210169e-02 train accuracy: 0.227082 val accuracy: 0.249000\n",
      "lr 1.701254e-04 reg 8.531679e-02 train accuracy: 0.305735 val accuracy: 0.307000\n",
      "lr 1.701254e-04 reg 1.172102e-01 train accuracy: 0.246469 val accuracy: 0.250000\n",
      "lr 1.701254e-04 reg 1.610262e-01 train accuracy: 0.216041 val accuracy: 0.201000\n",
      "lr 1.701254e-04 reg 2.212216e-01 train accuracy: 0.321551 val accuracy: 0.305000\n",
      "lr 1.701254e-04 reg 3.039195e-01 train accuracy: 0.295367 val accuracy: 0.294000\n",
      "lr 1.701254e-04 reg 4.175319e-01 train accuracy: 0.322959 val accuracy: 0.313000\n",
      "lr 1.701254e-04 reg 5.736153e-01 train accuracy: 0.258020 val accuracy: 0.267000\n",
      "lr 1.701254e-04 reg 7.880463e-01 train accuracy: 0.313776 val accuracy: 0.273000\n",
      "lr 1.701254e-04 reg 1.082637e+00 train accuracy: 0.273102 val accuracy: 0.272000\n",
      "lr 1.701254e-04 reg 1.487352e+00 train accuracy: 0.282265 val accuracy: 0.286000\n",
      "lr 1.701254e-04 reg 2.043360e+00 train accuracy: 0.263429 val accuracy: 0.275000\n",
      "lr 1.701254e-04 reg 2.807216e+00 train accuracy: 0.268918 val accuracy: 0.279000\n",
      "lr 1.701254e-04 reg 3.856620e+00 train accuracy: 0.303347 val accuracy: 0.292000\n",
      "lr 1.701254e-04 reg 5.298317e+00 train accuracy: 0.306551 val accuracy: 0.312000\n",
      "lr 1.701254e-04 reg 7.278954e+00 train accuracy: 0.222122 val accuracy: 0.239000\n",
      "lr 1.701254e-04 reg 1.000000e+01 train accuracy: 0.292796 val accuracy: 0.297000\n",
      "lr 2.424462e-04 reg 1.000000e-03 train accuracy: 0.267000 val accuracy: 0.267000\n",
      "lr 2.424462e-04 reg 1.373824e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-04 reg 1.887392e-03 train accuracy: 0.282959 val accuracy: 0.281000\n",
      "lr 2.424462e-04 reg 2.592944e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-04 reg 3.562248e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-04 reg 4.893901e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-04 reg 6.723358e-03 train accuracy: 0.278102 val accuracy: 0.272000\n",
      "lr 2.424462e-04 reg 9.236709e-03 train accuracy: 0.272122 val accuracy: 0.245000\n",
      "lr 2.424462e-04 reg 1.268961e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-04 reg 1.743329e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-04 reg 2.395027e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-04 reg 3.290345e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-04 reg 4.520354e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-04 reg 6.210169e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-04 reg 8.531679e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-04 reg 1.172102e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-04 reg 1.610262e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-04 reg 2.212216e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-04 reg 3.039195e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-04 reg 4.175319e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-04 reg 5.736153e-01 train accuracy: 0.289204 val accuracy: 0.273000\n",
      "lr 2.424462e-04 reg 7.880463e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-04 reg 1.082637e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-04 reg 1.487352e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-04 reg 2.043360e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-04 reg 2.807216e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-04 reg 3.856620e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-04 reg 5.298317e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-04 reg 7.278954e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-04 reg 1.000000e+01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-04 reg 1.000000e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-04 reg 1.373824e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-04 reg 1.887392e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-04 reg 2.592944e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-04 reg 3.562248e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-04 reg 4.893901e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-04 reg 6.723358e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-04 reg 9.236709e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-04 reg 1.268961e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-04 reg 1.743329e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-04 reg 2.395027e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-04 reg 3.290345e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-04 reg 4.520354e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-04 reg 6.210169e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-04 reg 8.531679e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-04 reg 1.172102e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-04 reg 1.610262e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-04 reg 2.212216e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-04 reg 3.039195e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-04 reg 4.175319e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-04 reg 5.736153e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-04 reg 7.880463e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-04 reg 1.082637e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-04 reg 1.487352e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-04 reg 2.043360e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-04 reg 2.807216e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-04 reg 3.856620e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-04 reg 5.298317e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-04 reg 7.278954e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-04 reg 1.000000e+01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-04 reg 1.000000e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-04 reg 1.373824e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-04 reg 1.887392e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-04 reg 2.592944e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-04 reg 3.562248e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-04 reg 4.893901e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-04 reg 6.723358e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-04 reg 9.236709e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-04 reg 1.268961e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-04 reg 1.743329e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-04 reg 2.395027e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-04 reg 3.290345e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-04 reg 4.520354e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-04 reg 6.210169e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-04 reg 8.531679e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-04 reg 1.172102e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-04 reg 1.610262e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-04 reg 2.212216e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-04 reg 3.039195e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-04 reg 4.175319e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-04 reg 5.736153e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-04 reg 7.880463e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-04 reg 1.082637e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-04 reg 1.487352e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-04 reg 2.043360e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-04 reg 2.807216e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-04 reg 3.856620e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-04 reg 5.298317e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-04 reg 7.278954e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-04 reg 1.000000e+01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-04 reg 1.000000e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-04 reg 1.373824e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-04 reg 1.887392e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-04 reg 2.592944e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-04 reg 3.562248e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-04 reg 4.893901e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-04 reg 6.723358e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-04 reg 9.236709e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-04 reg 1.268961e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-04 reg 1.743329e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-04 reg 2.395027e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-04 reg 3.290345e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-04 reg 4.520354e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-04 reg 6.210169e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-04 reg 8.531679e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-04 reg 1.172102e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-04 reg 1.610262e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-04 reg 2.212216e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-04 reg 3.039195e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-04 reg 4.175319e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-04 reg 5.736153e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-04 reg 7.880463e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-04 reg 1.082637e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-04 reg 1.487352e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-04 reg 2.043360e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-04 reg 2.807216e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-04 reg 3.856620e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-04 reg 5.298317e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-04 reg 7.278954e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-04 reg 1.000000e+01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-03 reg 1.000000e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-03 reg 1.373824e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-03 reg 1.887392e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-03 reg 2.592944e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-03 reg 3.562248e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-03 reg 4.893901e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-03 reg 6.723358e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-03 reg 9.236709e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-03 reg 1.268961e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-03 reg 1.743329e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-03 reg 2.395027e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-03 reg 3.290345e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-03 reg 4.520354e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-03 reg 6.210169e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-03 reg 8.531679e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-03 reg 1.172102e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-03 reg 1.610262e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-03 reg 2.212216e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-03 reg 3.039195e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-03 reg 4.175319e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-03 reg 5.736153e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-03 reg 7.880463e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-03 reg 1.082637e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-03 reg 1.487352e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-03 reg 2.043360e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-03 reg 2.807216e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-03 reg 3.856620e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-03 reg 5.298317e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-03 reg 7.278954e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-03 reg 1.000000e+01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-03 reg 1.000000e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-03 reg 1.373824e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-03 reg 1.887392e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-03 reg 2.592944e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-03 reg 3.562248e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-03 reg 4.893901e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-03 reg 6.723358e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-03 reg 9.236709e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-03 reg 1.268961e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-03 reg 1.743329e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-03 reg 2.395027e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-03 reg 3.290345e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-03 reg 4.520354e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-03 reg 6.210169e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-03 reg 8.531679e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-03 reg 1.172102e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-03 reg 1.610262e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-03 reg 2.212216e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-03 reg 3.039195e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-03 reg 4.175319e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-03 reg 5.736153e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-03 reg 7.880463e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-03 reg 1.082637e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-03 reg 1.487352e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-03 reg 2.043360e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-03 reg 2.807216e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-03 reg 3.856620e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-03 reg 5.298317e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-03 reg 7.278954e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-03 reg 1.000000e+01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-03 reg 1.000000e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-03 reg 1.373824e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-03 reg 1.887392e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-03 reg 2.592944e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-03 reg 3.562248e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-03 reg 4.893901e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-03 reg 6.723358e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-03 reg 9.236709e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-03 reg 1.268961e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-03 reg 1.743329e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-03 reg 2.395027e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-03 reg 3.290345e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-03 reg 4.520354e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-03 reg 6.210169e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-03 reg 8.531679e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-03 reg 1.172102e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-03 reg 1.610262e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-03 reg 2.212216e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-03 reg 3.039195e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-03 reg 4.175319e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-03 reg 5.736153e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-03 reg 7.880463e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-03 reg 1.082637e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-03 reg 1.487352e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-03 reg 2.043360e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-03 reg 2.807216e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-03 reg 3.856620e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-03 reg 5.298317e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-03 reg 7.278954e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-03 reg 1.000000e+01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-03 reg 1.000000e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-03 reg 1.373824e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-03 reg 1.887392e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-03 reg 2.592944e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-03 reg 3.562248e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-03 reg 4.893901e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-03 reg 6.723358e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-03 reg 9.236709e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-03 reg 1.268961e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-03 reg 1.743329e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-03 reg 2.395027e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-03 reg 3.290345e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-03 reg 4.520354e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-03 reg 6.210169e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-03 reg 8.531679e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-03 reg 1.172102e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-03 reg 1.610262e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-03 reg 2.212216e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-03 reg 3.039195e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-03 reg 4.175319e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-03 reg 5.736153e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-03 reg 7.880463e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-03 reg 1.082637e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-03 reg 1.487352e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-03 reg 2.043360e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-03 reg 2.807216e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-03 reg 3.856620e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-03 reg 5.298317e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-03 reg 7.278954e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-03 reg 1.000000e+01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-03 reg 1.000000e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-03 reg 1.373824e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-03 reg 1.887392e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-03 reg 2.592944e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-03 reg 3.562248e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-03 reg 4.893901e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-03 reg 6.723358e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-03 reg 9.236709e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-03 reg 1.268961e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-03 reg 1.743329e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-03 reg 2.395027e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-03 reg 3.290345e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-03 reg 4.520354e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-03 reg 6.210169e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-03 reg 8.531679e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-03 reg 1.172102e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-03 reg 1.610262e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-03 reg 2.212216e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-03 reg 3.039195e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-03 reg 4.175319e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-03 reg 5.736153e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-03 reg 7.880463e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-03 reg 1.082637e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-03 reg 1.487352e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-03 reg 2.043360e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-03 reg 2.807216e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-03 reg 3.856620e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-03 reg 5.298317e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-03 reg 7.278954e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-03 reg 1.000000e+01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-03 reg 1.000000e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-03 reg 1.373824e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-03 reg 1.887392e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-03 reg 2.592944e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-03 reg 3.562248e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-03 reg 4.893901e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-03 reg 6.723358e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-03 reg 9.236709e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-03 reg 1.268961e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-03 reg 1.743329e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-03 reg 2.395027e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-03 reg 3.290345e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-03 reg 4.520354e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-03 reg 6.210169e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-03 reg 8.531679e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-03 reg 1.172102e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-03 reg 1.610262e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-03 reg 2.212216e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-03 reg 3.039195e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-03 reg 4.175319e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-03 reg 5.736153e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-03 reg 7.880463e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-03 reg 1.082637e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-03 reg 1.487352e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-03 reg 2.043360e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-03 reg 2.807216e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-03 reg 3.856620e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-03 reg 5.298317e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-03 reg 7.278954e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-03 reg 1.000000e+01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-03 reg 1.000000e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-03 reg 1.373824e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-03 reg 1.887392e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-03 reg 2.592944e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-03 reg 3.562248e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-03 reg 4.893901e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-03 reg 6.723358e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-03 reg 9.236709e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-03 reg 1.268961e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-03 reg 1.743329e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-03 reg 2.395027e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-03 reg 3.290345e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-03 reg 4.520354e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-03 reg 6.210169e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-03 reg 8.531679e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-03 reg 1.172102e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-03 reg 1.610262e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-03 reg 2.212216e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-03 reg 3.039195e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-03 reg 4.175319e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-03 reg 5.736153e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-03 reg 7.880463e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-03 reg 1.082637e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-03 reg 1.487352e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-03 reg 2.043360e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-03 reg 2.807216e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-03 reg 3.856620e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-03 reg 5.298317e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-03 reg 7.278954e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-03 reg 1.000000e+01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e-02 reg 1.000000e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e-02 reg 1.373824e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e-02 reg 1.887392e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e-02 reg 2.592944e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e-02 reg 3.562248e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e-02 reg 4.893901e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e-02 reg 6.723358e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e-02 reg 9.236709e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e-02 reg 1.268961e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e-02 reg 1.743329e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e-02 reg 2.395027e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e-02 reg 3.290345e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e-02 reg 4.520354e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e-02 reg 6.210169e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e-02 reg 8.531679e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e-02 reg 1.172102e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e-02 reg 1.610262e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e-02 reg 2.212216e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e-02 reg 3.039195e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e-02 reg 4.175319e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e-02 reg 5.736153e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e-02 reg 7.880463e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e-02 reg 1.082637e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e-02 reg 1.487352e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e-02 reg 2.043360e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e-02 reg 2.807216e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e-02 reg 3.856620e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e-02 reg 5.298317e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e-02 reg 7.278954e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e-02 reg 1.000000e+01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e-02 reg 1.000000e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e-02 reg 1.373824e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e-02 reg 1.887392e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e-02 reg 2.592944e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e-02 reg 3.562248e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e-02 reg 4.893901e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e-02 reg 6.723358e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e-02 reg 9.236709e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e-02 reg 1.268961e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e-02 reg 1.743329e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e-02 reg 2.395027e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e-02 reg 3.290345e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e-02 reg 4.520354e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e-02 reg 6.210169e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e-02 reg 8.531679e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e-02 reg 1.172102e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e-02 reg 1.610262e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e-02 reg 2.212216e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e-02 reg 3.039195e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e-02 reg 4.175319e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e-02 reg 5.736153e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e-02 reg 7.880463e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e-02 reg 1.082637e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e-02 reg 1.487352e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e-02 reg 2.043360e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e-02 reg 2.807216e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e-02 reg 3.856620e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e-02 reg 5.298317e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e-02 reg 7.278954e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e-02 reg 1.000000e+01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-02 reg 1.000000e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-02 reg 1.373824e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-02 reg 1.887392e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-02 reg 2.592944e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-02 reg 3.562248e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-02 reg 4.893901e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-02 reg 6.723358e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-02 reg 9.236709e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-02 reg 1.268961e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-02 reg 1.743329e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-02 reg 2.395027e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-02 reg 3.290345e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-02 reg 4.520354e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-02 reg 6.210169e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-02 reg 8.531679e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-02 reg 1.172102e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-02 reg 1.610262e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-02 reg 2.212216e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-02 reg 3.039195e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-02 reg 4.175319e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-02 reg 5.736153e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-02 reg 7.880463e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-02 reg 1.082637e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-02 reg 1.487352e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-02 reg 2.043360e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-02 reg 2.807216e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-02 reg 3.856620e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-02 reg 5.298317e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-02 reg 7.278954e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e-02 reg 1.000000e+01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-02 reg 1.000000e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-02 reg 1.373824e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-02 reg 1.887392e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-02 reg 2.592944e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-02 reg 3.562248e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-02 reg 4.893901e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-02 reg 6.723358e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-02 reg 9.236709e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-02 reg 1.268961e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-02 reg 1.743329e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-02 reg 2.395027e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-02 reg 3.290345e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-02 reg 4.520354e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-02 reg 6.210169e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-02 reg 8.531679e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-02 reg 1.172102e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-02 reg 1.610262e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-02 reg 2.212216e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-02 reg 3.039195e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-02 reg 4.175319e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-02 reg 5.736153e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-02 reg 7.880463e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-02 reg 1.082637e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-02 reg 1.487352e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-02 reg 2.043360e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-02 reg 2.807216e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-02 reg 3.856620e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-02 reg 5.298317e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-02 reg 7.278954e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e-02 reg 1.000000e+01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-02 reg 1.000000e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-02 reg 1.373824e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-02 reg 1.887392e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-02 reg 2.592944e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-02 reg 3.562248e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-02 reg 4.893901e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-02 reg 6.723358e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-02 reg 9.236709e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-02 reg 1.268961e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-02 reg 1.743329e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-02 reg 2.395027e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-02 reg 3.290345e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-02 reg 4.520354e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-02 reg 6.210169e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-02 reg 8.531679e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-02 reg 1.172102e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-02 reg 1.610262e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-02 reg 2.212216e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-02 reg 3.039195e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-02 reg 4.175319e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-02 reg 5.736153e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-02 reg 7.880463e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-02 reg 1.082637e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-02 reg 1.487352e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-02 reg 2.043360e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-02 reg 2.807216e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-02 reg 3.856620e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-02 reg 5.298317e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-02 reg 7.278954e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e-02 reg 1.000000e+01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-02 reg 1.000000e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-02 reg 1.373824e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-02 reg 1.887392e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-02 reg 2.592944e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-02 reg 3.562248e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-02 reg 4.893901e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-02 reg 6.723358e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-02 reg 9.236709e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-02 reg 1.268961e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-02 reg 1.743329e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-02 reg 2.395027e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-02 reg 3.290345e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-02 reg 4.520354e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-02 reg 6.210169e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-02 reg 8.531679e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-02 reg 1.172102e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-02 reg 1.610262e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-02 reg 2.212216e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-02 reg 3.039195e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-02 reg 4.175319e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-02 reg 5.736153e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-02 reg 7.880463e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-02 reg 1.082637e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-02 reg 1.487352e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-02 reg 2.043360e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-02 reg 2.807216e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-02 reg 3.856620e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-02 reg 5.298317e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-02 reg 7.278954e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e-02 reg 1.000000e+01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-01 reg 1.000000e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-01 reg 1.373824e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-01 reg 1.887392e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-01 reg 2.592944e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-01 reg 3.562248e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-01 reg 4.893901e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-01 reg 6.723358e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-01 reg 9.236709e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-01 reg 1.268961e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-01 reg 1.743329e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-01 reg 2.395027e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-01 reg 3.290345e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-01 reg 4.520354e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-01 reg 6.210169e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-01 reg 8.531679e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-01 reg 1.172102e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-01 reg 1.610262e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-01 reg 2.212216e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-01 reg 3.039195e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-01 reg 4.175319e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-01 reg 5.736153e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-01 reg 7.880463e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-01 reg 1.082637e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-01 reg 1.487352e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-01 reg 2.043360e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-01 reg 2.807216e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-01 reg 3.856620e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-01 reg 5.298317e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-01 reg 7.278954e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-01 reg 1.000000e+01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-01 reg 1.000000e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-01 reg 1.373824e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-01 reg 1.887392e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-01 reg 2.592944e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-01 reg 3.562248e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-01 reg 4.893901e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-01 reg 6.723358e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-01 reg 9.236709e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-01 reg 1.268961e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-01 reg 1.743329e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-01 reg 2.395027e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-01 reg 3.290345e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-01 reg 4.520354e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-01 reg 6.210169e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-01 reg 8.531679e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-01 reg 1.172102e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-01 reg 1.610262e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-01 reg 2.212216e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-01 reg 3.039195e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-01 reg 4.175319e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-01 reg 5.736153e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-01 reg 7.880463e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-01 reg 1.082637e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-01 reg 1.487352e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-01 reg 2.043360e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-01 reg 2.807216e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-01 reg 3.856620e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-01 reg 5.298317e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-01 reg 7.278954e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.425103e-01 reg 1.000000e+01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-01 reg 1.000000e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-01 reg 1.373824e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-01 reg 1.887392e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-01 reg 2.592944e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-01 reg 3.562248e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-01 reg 4.893901e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-01 reg 6.723358e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-01 reg 9.236709e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-01 reg 1.268961e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-01 reg 1.743329e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-01 reg 2.395027e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-01 reg 3.290345e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-01 reg 4.520354e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-01 reg 6.210169e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-01 reg 8.531679e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-01 reg 1.172102e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-01 reg 1.610262e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-01 reg 2.212216e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-01 reg 3.039195e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-01 reg 4.175319e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-01 reg 5.736153e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-01 reg 7.880463e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-01 reg 1.082637e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-01 reg 1.487352e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-01 reg 2.043360e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-01 reg 2.807216e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-01 reg 3.856620e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-01 reg 5.298317e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-01 reg 7.278954e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.030918e-01 reg 1.000000e+01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-01 reg 1.000000e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-01 reg 1.373824e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-01 reg 1.887392e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-01 reg 2.592944e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-01 reg 3.562248e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-01 reg 4.893901e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-01 reg 6.723358e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-01 reg 9.236709e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-01 reg 1.268961e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-01 reg 1.743329e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-01 reg 2.395027e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-01 reg 3.290345e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-01 reg 4.520354e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-01 reg 6.210169e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-01 reg 8.531679e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-01 reg 1.172102e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-01 reg 1.610262e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-01 reg 2.212216e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-01 reg 3.039195e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-01 reg 4.175319e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-01 reg 5.736153e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-01 reg 7.880463e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-01 reg 1.082637e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-01 reg 1.487352e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-01 reg 2.043360e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-01 reg 2.807216e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-01 reg 3.856620e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-01 reg 5.298317e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-01 reg 7.278954e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.894266e-01 reg 1.000000e+01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-01 reg 1.000000e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-01 reg 1.373824e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-01 reg 1.887392e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-01 reg 2.592944e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-01 reg 3.562248e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-01 reg 4.893901e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-01 reg 6.723358e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-01 reg 9.236709e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-01 reg 1.268961e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-01 reg 1.743329e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-01 reg 2.395027e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-01 reg 3.290345e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-01 reg 4.520354e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-01 reg 6.210169e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-01 reg 8.531679e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-01 reg 1.172102e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-01 reg 1.610262e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-01 reg 2.212216e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-01 reg 3.039195e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-01 reg 4.175319e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-01 reg 5.736153e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-01 reg 7.880463e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-01 reg 1.082637e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-01 reg 1.487352e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-01 reg 2.043360e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-01 reg 2.807216e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-01 reg 3.856620e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-01 reg 5.298317e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-01 reg 7.278954e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.124626e-01 reg 1.000000e+01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-01 reg 1.000000e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-01 reg 1.373824e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-01 reg 1.887392e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-01 reg 2.592944e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-01 reg 3.562248e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-01 reg 4.893901e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-01 reg 6.723358e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-01 reg 9.236709e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-01 reg 1.268961e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-01 reg 1.743329e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-01 reg 2.395027e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-01 reg 3.290345e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-01 reg 4.520354e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-01 reg 6.210169e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-01 reg 8.531679e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-01 reg 1.172102e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-01 reg 1.610262e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-01 reg 2.212216e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-01 reg 3.039195e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-01 reg 4.175319e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-01 reg 5.736153e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-01 reg 7.880463e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-01 reg 1.082637e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-01 reg 1.487352e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-01 reg 2.043360e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-01 reg 2.807216e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-01 reg 3.856620e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-01 reg 5.298317e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-01 reg 7.278954e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.878016e-01 reg 1.000000e+01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-01 reg 1.000000e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-01 reg 1.373824e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-01 reg 1.887392e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-01 reg 2.592944e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-01 reg 3.562248e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-01 reg 4.893901e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-01 reg 6.723358e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-01 reg 9.236709e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-01 reg 1.268961e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-01 reg 1.743329e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-01 reg 2.395027e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-01 reg 3.290345e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-01 reg 4.520354e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-01 reg 6.210169e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-01 reg 8.531679e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-01 reg 1.172102e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-01 reg 1.610262e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-01 reg 2.212216e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-01 reg 3.039195e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-01 reg 4.175319e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-01 reg 5.736153e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-01 reg 7.880463e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-01 reg 1.082637e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-01 reg 1.487352e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-01 reg 2.043360e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-01 reg 2.807216e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-01 reg 3.856620e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-01 reg 5.298317e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-01 reg 7.278954e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 8.376776e-01 reg 1.000000e+01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e+00 reg 1.000000e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e+00 reg 1.373824e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e+00 reg 1.887392e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e+00 reg 2.592944e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e+00 reg 3.562248e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e+00 reg 4.893901e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e+00 reg 6.723358e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e+00 reg 9.236709e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e+00 reg 1.268961e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e+00 reg 1.743329e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e+00 reg 2.395027e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e+00 reg 3.290345e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e+00 reg 4.520354e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e+00 reg 6.210169e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e+00 reg 8.531679e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e+00 reg 1.172102e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e+00 reg 1.610262e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e+00 reg 2.212216e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e+00 reg 3.039195e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e+00 reg 4.175319e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e+00 reg 5.736153e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e+00 reg 7.880463e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e+00 reg 1.082637e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e+00 reg 1.487352e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e+00 reg 2.043360e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e+00 reg 2.807216e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e+00 reg 3.856620e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e+00 reg 5.298317e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e+00 reg 7.278954e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.193777e+00 reg 1.000000e+01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e+00 reg 1.000000e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e+00 reg 1.373824e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e+00 reg 1.887392e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e+00 reg 2.592944e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e+00 reg 3.562248e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e+00 reg 4.893901e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e+00 reg 6.723358e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e+00 reg 9.236709e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e+00 reg 1.268961e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e+00 reg 1.743329e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e+00 reg 2.395027e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e+00 reg 3.290345e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e+00 reg 4.520354e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e+00 reg 6.210169e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e+00 reg 8.531679e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e+00 reg 1.172102e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e+00 reg 1.610262e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e+00 reg 2.212216e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e+00 reg 3.039195e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e+00 reg 4.175319e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e+00 reg 5.736153e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e+00 reg 7.880463e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e+00 reg 1.082637e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e+00 reg 1.487352e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e+00 reg 2.043360e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e+00 reg 2.807216e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e+00 reg 3.856620e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e+00 reg 5.298317e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e+00 reg 7.278954e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.701254e+00 reg 1.000000e+01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e+00 reg 1.000000e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e+00 reg 1.373824e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e+00 reg 1.887392e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e+00 reg 2.592944e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e+00 reg 3.562248e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e+00 reg 4.893901e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e+00 reg 6.723358e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e+00 reg 9.236709e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e+00 reg 1.268961e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e+00 reg 1.743329e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e+00 reg 2.395027e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e+00 reg 3.290345e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e+00 reg 4.520354e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e+00 reg 6.210169e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e+00 reg 8.531679e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e+00 reg 1.172102e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e+00 reg 1.610262e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e+00 reg 2.212216e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e+00 reg 3.039195e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e+00 reg 4.175319e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e+00 reg 5.736153e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e+00 reg 7.880463e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e+00 reg 1.082637e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e+00 reg 1.487352e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e+00 reg 2.043360e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e+00 reg 2.807216e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e+00 reg 3.856620e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e+00 reg 5.298317e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e+00 reg 7.278954e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 2.424462e+00 reg 1.000000e+01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e+00 reg 1.000000e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e+00 reg 1.373824e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e+00 reg 1.887392e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e+00 reg 2.592944e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e+00 reg 3.562248e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e+00 reg 4.893901e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e+00 reg 6.723358e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e+00 reg 9.236709e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e+00 reg 1.268961e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e+00 reg 1.743329e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e+00 reg 2.395027e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e+00 reg 3.290345e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e+00 reg 4.520354e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e+00 reg 6.210169e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e+00 reg 8.531679e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e+00 reg 1.172102e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e+00 reg 1.610262e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e+00 reg 2.212216e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e+00 reg 3.039195e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e+00 reg 4.175319e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e+00 reg 5.736153e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e+00 reg 7.880463e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e+00 reg 1.082637e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e+00 reg 1.487352e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e+00 reg 2.043360e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e+00 reg 2.807216e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e+00 reg 3.856620e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e+00 reg 5.298317e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e+00 reg 7.278954e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.455107e+00 reg 1.000000e+01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e+00 reg 1.000000e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e+00 reg 1.373824e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e+00 reg 1.887392e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e+00 reg 2.592944e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e+00 reg 3.562248e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e+00 reg 4.893901e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e+00 reg 6.723358e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e+00 reg 9.236709e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e+00 reg 1.268961e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e+00 reg 1.743329e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e+00 reg 2.395027e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e+00 reg 3.290345e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e+00 reg 4.520354e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e+00 reg 6.210169e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e+00 reg 8.531679e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e+00 reg 1.172102e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e+00 reg 1.610262e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e+00 reg 2.212216e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e+00 reg 3.039195e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e+00 reg 4.175319e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e+00 reg 5.736153e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e+00 reg 7.880463e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e+00 reg 1.082637e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e+00 reg 1.487352e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e+00 reg 2.043360e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e+00 reg 2.807216e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e+00 reg 3.856620e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e+00 reg 5.298317e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e+00 reg 7.278954e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 4.923883e+00 reg 1.000000e+01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e+00 reg 1.000000e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e+00 reg 1.373824e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e+00 reg 1.887392e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e+00 reg 2.592944e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e+00 reg 3.562248e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e+00 reg 4.893901e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e+00 reg 6.723358e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e+00 reg 9.236709e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e+00 reg 1.268961e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e+00 reg 1.743329e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e+00 reg 2.395027e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e+00 reg 3.290345e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e+00 reg 4.520354e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e+00 reg 6.210169e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e+00 reg 8.531679e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e+00 reg 1.172102e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e+00 reg 1.610262e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e+00 reg 2.212216e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e+00 reg 3.039195e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e+00 reg 4.175319e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e+00 reg 5.736153e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e+00 reg 7.880463e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e+00 reg 1.082637e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e+00 reg 1.487352e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e+00 reg 2.043360e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e+00 reg 2.807216e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e+00 reg 3.856620e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e+00 reg 5.298317e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e+00 reg 7.278954e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 7.017038e+00 reg 1.000000e+01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+01 reg 1.000000e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+01 reg 1.373824e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+01 reg 1.887392e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+01 reg 2.592944e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+01 reg 3.562248e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+01 reg 4.893901e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+01 reg 6.723358e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+01 reg 9.236709e-03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+01 reg 1.268961e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+01 reg 1.743329e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+01 reg 2.395027e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+01 reg 3.290345e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+01 reg 4.520354e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+01 reg 6.210169e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+01 reg 8.531679e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+01 reg 1.172102e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+01 reg 1.610262e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+01 reg 2.212216e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+01 reg 3.039195e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+01 reg 4.175319e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+01 reg 5.736153e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+01 reg 7.880463e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+01 reg 1.082637e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+01 reg 1.487352e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+01 reg 2.043360e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+01 reg 2.807216e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+01 reg 3.856620e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+01 reg 5.298317e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+01 reg 7.278954e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+01 reg 1.000000e+01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "best validation accuracy achieved during cross-validation: 0.349000\n"
     ]
    }
   ],
   "source": [
    "# Use the validation set to tune hyperparameters (regularization strength and\n",
    "# learning rate). You should experiment with different ranges for the learning\n",
    "# rates and regularization strengths; if you are careful you should be able to\n",
    "# get a classification accuracy of over 0.35 on the validation set.\n",
    "from cs231n.classifiers import Softmax\n",
    "results = {}\n",
    "best_val = -1\n",
    "best_softmax = None\n",
    "learning_rates = np.logspace(-5, 1, 40)\n",
    "regularization_strengths = np.logspace(-3, 1, 30)\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Use the validation set to set the learning rate and regularization strength. #\n",
    "# This should be identical to the validation that you did for the SVM; save    #\n",
    "# the best trained softmax classifer in best_softmax.                          #\n",
    "################################################################################\n",
    "iters = 500 #100\n",
    "for lr in learning_rates:\n",
    "    for rs in regularization_strengths:\n",
    "        softmax = Softmax()\n",
    "        print 'X_train', X_train.shape\n",
    "        softmax.train(X_train, y_train, learning_rate=lr, reg=rs, num_iters=iters)\n",
    "        \n",
    "        y_train_pred = softmax.predict(X_train)\n",
    "        acc_train = np.mean(y_train == y_train_pred)\n",
    "        y_val_pred = softmax.predict(X_val)\n",
    "        acc_val = np.mean(y_val == y_val_pred)\n",
    "        \n",
    "        results[(lr, rs)] = (acc_train, acc_val)\n",
    "        \n",
    "        if best_val < acc_val:\n",
    "            best_val = acc_val\n",
    "            best_softmax = softmax\n",
    "    \n",
    "################################################################################\n",
    "#                              END OF YOUR CODE                                #\n",
    "################################################################################\n",
    "    \n",
    "# Print out results.\n",
    "for lr, reg in sorted(results):\n",
    "    train_accuracy, val_accuracy = results[(lr, reg)]\n",
    "    print 'lr %e reg %e train accuracy: %f val accuracy: %f' % (\n",
    "                lr, reg, train_accuracy, val_accuracy)\n",
    "    \n",
    "print 'best validation accuracy achieved during cross-validation: %f' % best_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax on raw pixels final test set accuracy: 0.333000\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "# Evaluate the best softmax on test set\n",
    "y_test_pred = best_softmax.predict(X_test)\n",
    "test_accuracy = np.mean(y_test == y_test_pred)\n",
    "print 'softmax on raw pixels final test set accuracy: %f' % (test_accuracy, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk8AAAF/CAYAAABQVS1eAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMWYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111d91c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the learned weights for each class\n",
    "w = best_softmax.W[:-1,:] # strip out the bias\n",
    "w = w.reshape(32, 32, 3, 10)\n",
    "\n",
    "w_min, w_max = np.min(w), np.max(w)\n",
    "\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "for i in xrange(10):\n",
    "  plt.subplot(2, 5, i + 1)\n",
    "  \n",
    "  # Rescale the weights to be between 0 and 255\n",
    "  wimg = 255.0 * (w[:, :, :, i].squeeze() - w_min) / (w_max - w_min)\n",
    "  plt.imshow(wimg.astype('uint8'))\n",
    "  plt.axis('off')\n",
    "  plt.title(classes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
